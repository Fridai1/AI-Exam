{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>AI-Exam</h1>\n",
    "<p>For this exam project we decided to work with natural language processing. We wanted to determine if a strong correlation could be made between the \"overview\" of a movie and its genre. The overall idea was to make the genre of the movies our <i>dependable variable</i>. We transformed all genres into numeric values, so that each number represents a different genre, then we broke down the description of each movie, by removing all stop words. Afterwards we checked how frequently the remaining words appeared in each movie overview, and assigned them a \"weight\" accordingly. This way we would be able to predict the genre of a movie, based off of the movie overview itself.</p>\n",
    "\n",
    "<h2>The dataset</h2>\n",
    "We've downloaded a dataset from kaggle, which can be found <a href=\"https://www.kaggle.com/tmdb/tmdb-movie-metadata\">here</a>. The dataset contains movies from <a href=\"https://www.imdb.com/\">IMDb</a>, and meta data about them. Most importantly it contains movies with their corresponding genres and a brief overview about them. Initially we used another dataset where each movie was associated with one genre, but we got inacuarate results. We suspected the inaccuracies was due to the size of the dataset. This was somewhat confirmed by the change of dataset, seeing as our models improved across the board after changing to a larger dataset. However the change did not come without issues. As briefly mentioned, in the initial dataset all movies were only related to <b>one</b> genre, whereas in the new dataset a movie could be related to <b>several</b> genres. This is an issue, as we can only have one dependable variable. To get around this issue, we decided that the first genre in the genre array, would be the movies genre, well knowing that the result potentially would be varying, as there's no guarantee that the first genre in the array is the genre that fits the movie best. Furthermore it also means that our algorithm potentially guesses correct with the second or third, or even fourth genre, but it would still be classified as a false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mwe1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "import pandas as pd\n",
    "import re #Regular expresion\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import nltk #Natural language processing tool kit\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Modelling\n",
    "from sklearn import model_selection, preprocessing, naive_bayes, metrics, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Helper methods</h2>\n",
    "<p>Three different helper methods has been developed during this project, to get the best possible results.</p>\n",
    "\n",
    "<h3>train_model</h3>\n",
    "<p>The 'train_model' method was developed to get an easier overview, seeing as we're training a bunch of different models, which are all trained in the same way. The method takes the following parameters: classfier, X_train, y_train and X_test.</p>\n",
    "\n",
    "<h3>convert_arr_to_list</h3>\n",
    "<p>As the method name suggests, the method takes an array and converts it to a list.</p>\n",
    "\n",
    "<h3>transform_genre</h3>\n",
    "<p>TBD</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper methods\n",
    "def train_model(classifier, X_train, y_train, X_test):\n",
    "    \n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    pred = classifier.predict(X_test)\n",
    "                              \n",
    "    return metrics.accuracy_score(y_test, pred)\n",
    "                              \n",
    "def convert_arr_to_list(arr):\n",
    "    lst = []\n",
    "    for i in arr:\n",
    "        lst.append(i)\n",
    "    return lst\n",
    "\n",
    "def transform_genre(arr):\n",
    "    arr = [[],[]]\n",
    "    failedIndexes = []\n",
    "    counter = 0\n",
    "    while counter < len(arr):\n",
    "        try:\n",
    "            genreObject = array[counter]\n",
    "            genreStr = genreObject[0]            \n",
    "            genreStr = genreStr.replace('[', '')\n",
    "            genreStr = genreStr.replace(']','')\n",
    "            splitStr = genreStr.split('}, {')\n",
    "            arr.append(counter)\n",
    "            splitStr[0] = splitStr[0].replace('{', '')\n",
    "            length = len(splitStr)\n",
    "            splitStr[length-1] = splitStr[length-1].replace('}', '')\n",
    "            for i in splitStr:\n",
    "                i = \"{\"+i+\"}\"\n",
    "                jsonobj = json.loads(i)\n",
    "                genre = jsonobj[\"name\"]\n",
    "                arr[counter].append(genre)                      \n",
    "            counter += 1 \n",
    "        except:\n",
    "            failedIndexes.sort()\n",
    "            failedIndexes = failedIndexes[::-1] # reversing the list\n",
    "            counter += 1\n",
    "    return arr, failedIndexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data pre-processing</h2>\n",
    "<p>Kaggle gave us the option to select which columns we would like to download, hence the dataset came with only two columns out of the box; genre and overview. Which means we didn't have to make this split programatically. As briefly touched upon in the introduction, a movie could be associated with several genres, which was represented by a genre array. As an example a movie could be both a Sci-fi and an Action movie, which also seems rather logical. As we've also mentioned the order of the genres doesn't nessecarily mean anything in terms of genre specificity, and this is important, as it makes our results error-prone. We converted the ovewview and the genres into lists which were previously stored in a dataframe.\n",
    "\n",
    "Initally we created two empty lists, one list to hold all the genres that aren't empty, as well as a list to keep track of the indexes of genres that contained no data. We then iterate trough all the elements in the list of genres (y_list). We've defined a try/except clause, where, if possible, we store something we've called an \"genreObject\" which is actually a list of list only containing one element. We grab that one element in the list, which we've named \"genreStr\", this element looks like a array of json objects, but is in reality a poorly formatted string. We then contiue to split the poorly formatted string on white spaces, and grab the element at index position three, which is always the genre, given it's present. We then use regex to remove unwanted characters. As a biproduct of using regexs findall(), which return a list, we select the processed string by selecting the element at index 0 in the returned list. Said element is then added to a new list which we've called \"y_\", and finally we increment the counter, and repeat this process until we have all of the genres. Given the genre array is empty we hit the except clause, where we store the index of the missing genre, and increment the counter and continue the while loop.\n",
    "\n",
    "We now grab the list of failed indexes and sort it, using pythons inbuilt sort() method, which is possible because it's numeric data. We then reverse the array using slicing. This is nessecary, otherwise when we start removing rows in the list, the loop would crash itself, if we removed indexes from low to high. We now itterate trough the list of overviews and remove all of the overviews with the same index position as the missing genres, this is nessecary because the two list has to be same length.\n",
    "\n",
    "Now we create an empty list called X_ and repeat the process mentioned above, now only with overviews instead. We still had nan values in the X_list, so we converted X_list to a dataframe, and used isNull() which returns a bool, and stored those indexes that returned true, and removed them accordingly from both X_list and y_list.\n",
    "\n",
    "Now were ready to fit and transform the models, so we split the datasets in test and traning batches and used fit_transform() on the labelenconder.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesDF = pd.read_csv('tmdb_movies.csv') \n",
    "\n",
    "# RETURN TO THIS LATER\n",
    "# moviesDF.groupby('genres').size() # prints how many of each genre there exists\n",
    "\n",
    "\n",
    "y = moviesDF[['genres']] # our dependent variable\n",
    "\n",
    "X = moviesDF[['overview']] # our independant variable\n",
    "\n",
    "X_list = X.values.tolist()\n",
    "y_list = y.values.tolist()\n",
    "\n",
    "#result, failed = TransformGenre(y_list)\n",
    "\n",
    "y_ = [] # temp, array for genres that arent empty\n",
    "failedIndexes = [] # array to keep track of the index we had an empty genre, to be used later in deletion.\n",
    "\n",
    "counter = 0\n",
    "# we iterate over y_list to find all genres that arent empty, if one is empty its gonna trigger an exception\n",
    "# which triggers our except clause. The except clause saved the index the error empty genre was located and progresses the counter\n",
    "while counter < len(y_list):\n",
    "    try:\n",
    "        genreObject = y_list[counter]\n",
    "        genreStr = genreObject[0]\n",
    "        strstr = genreStr.split()\n",
    "        indexedstr = strstr[3]\n",
    "        finalStr = re.findall(r'\\w+', indexedstr)    \n",
    "        y_.append(finalStr[0])\n",
    "        counter += 1 \n",
    "    except:\n",
    "        failedIndexes.append(counter)\n",
    "        counter += 1\n",
    "        \n",
    "failedIndexes.sort()\n",
    "failedIndexes = failedIndexes[::-1] # reversing the list\n",
    "# as it turns out when you delete an index from a python list, it collapses the list, so we had to delete the highest index first to circumvent this.\n",
    "for index in failedIndexes:\n",
    "    del X_list[index]\n",
    "\n",
    "X_ =  [] # temp list to contain all strings\n",
    "failedIndexes = []\n",
    "counter = 0\n",
    "# Currently X_list contains a collection of collections, this kind of list-ception is incompatible with the AI algorithm\n",
    "# So we create this small loop to extract the string.\n",
    "while counter < len(X_list):\n",
    "    listLine = X_list[counter]\n",
    "    listString = listLine[0]\n",
    "    if not listString:\n",
    "        failedIndexes.append(counter)\n",
    "        counter += 1\n",
    "        continue\n",
    "    X_.append(listString)\n",
    "    counter += 1\n",
    "    \n",
    "failedIndexes = failedIndexes[::-1]\n",
    "for i in failedIndexes:\n",
    "    del y_[i]\n",
    "    \n",
    "y_list = y_\n",
    "X_list = X_\n",
    "\n",
    "# We had nan values in our X_list, we decided to convert the X_list back to a dataframe\n",
    "# in order to run isnull(), which returns a list of false/true wether an entry is nan or not\n",
    "# with this we simply saved the index of which the nan occured and deleted\n",
    "# it from both our dependant and independant variable.\n",
    "\n",
    "tempDf = pd.DataFrame(X_list)\n",
    "boolList = tempDf.isnull().values\n",
    "\n",
    "badIndexes = []\n",
    "counter = 0\n",
    "while counter < len(boolList):\n",
    "    if boolList[counter][0]:\n",
    "        badIndexes.append(counter)               \n",
    "    counter += 1\n",
    "\n",
    "badIndexes = badIndexes[::-1]\n",
    "\n",
    "for i in badIndexes:\n",
    "    del X_list[i]\n",
    "    del y_list[i]\n",
    "        \n",
    "# we are splitting our dataset up here for training and later validation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_list,y_list)\n",
    "\n",
    "# Encoder to encode our dependant variable\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Engineering</h2>\n",
    "<p>Count Vector is a matrix notation of the dataset in which every row represents a document from the corpus, where corpus roughly translates to the training data. The Count Vector generates a vocabulary based on the matrix in which every row represents a term from the corpus and has a corresponding value representing the frequency count of a particular term. The count vectors have several different parameters which can be adjusted to yield different results, sometimes it's just about adjusting a parameter slightly, which can cause high variance.</p>\n",
    "\n",
    "<h3>analyzer</h3>\n",
    "<p>Analyzer is a parameter we set to equal to 'word'. Which means we only consider words, alternatively one could consider every single char, given 'char'.</p>\n",
    "\n",
    "<h3>stop_words</h3>\n",
    "<p>We tried using the built-in stopwords from the scikit toolkit, which can be accessed by setting the stop_words parameter equal to 'english'. Taking a closer look at the stopwords, we felt they were insufficient, and briefly we considered making our own stopwords, until we realized how much of a hassle that would be. Nltk, Natural Language Toolkit, also offers a list of stopwords, which we tried using, but the results were indifferent.<p/>\n",
    "\n",
    "<h3>token_pattern</h3>\n",
    "<p>Furthermore we tried adjusting the token pattern, which is a regular expression, expressing when a word is valid/to be considered i.e having a token pattern like: '\\w{1,}', means that all words with more than one character is considered. Where as if we change the pattern to '\\w{3,}', we would only consider words with four or more characters. Finally we also tried restricting the characters themselves, by adding the following to our token: '\\w{x,}[a-z]' which essentially means we only consider characters between and a-z, not numbers nor special characters. We played around with different combinations, but found that not providing a token at all yielded the most consistent results.<p/>\n",
    "    \n",
    "<h3>ngram_range</h3>    \n",
    "<p>ngram_range defines how many words in a sentence are to be considered as a 'unit'. Consider the following sentence: \"The mighty lion sleeps tonight\". If ngram_range was set to (1,2), the output of the sentence would be: \"The\":x, \"mighty\":x, ... \"The mighty\":x, \"mighty lion\":x, and so on. Adjusting this parameter clearly affected our results, and we would the most consistent result using ngram_range=(1,3). We opted out of using this parameter, because using analyzer='word' yielded better results.</p>\n",
    "    \n",
    "<h3>max_features</h3>\n",
    "<p>Adjusting this setting changes the number of total features we would consider, again a parameter that clearly affected our results, and essentially we stopped playing with it, and settled at 5000, where we seemed to get consistent results.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words = set(stopwords.words('english'))\n",
    "#token = 'r\\w{4,}[a-z]'\n",
    "\n",
    "count_vect = CountVectorizer(analyzer='word', stop_words='english', max_features=5000)\n",
    "count_vect.fit(X_train)\n",
    "# Now we are gonna transform the training and test data with our vectorized object\n",
    "\n",
    "X_train_count = count_vect.transform(X_train)\n",
    "X_test_count = count_vect.transform(X_test)\n",
    "\n",
    "# Now we are gonna use Term Frequency - Inverted Document Frequence (TF-IDF) vectors as features\n",
    "# The score generate by the TF-IDF represents the relatuve importance of a term in a document and the entire corpus.\n",
    "# We generate this score in two steps:\n",
    "# The first computes the normalizeds term frequency (Tf) --- TF(x) = Number of times x appears in the document / total bynber if terms in the document. \n",
    "# the second computes the inverse document frequency  (IDF) --- IDF(x) = log_e(total number of documents / number of documents with term x in it)\n",
    "# as mentioned earlier we could have chosen to use an n-gram composed of words, which we have implemented in line 61.\n",
    "# now we are creating the TF-IDF score based on that n-gram.\n",
    "\n",
    "#tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern='\\w{1,}', max_features=5000)\n",
    "tfidf_vect = TfidfVectorizer(encoding='utf-8',lowercase=True, stop_words='english', sublinear_tf=True, use_idf=True,max_features=5000)\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training and testing</h2>\n",
    "<p>To train and test our models we used the helper methods that we developed earlier on. To compare the results of the different models we printed out the accuracy of each model after it ran.</p>\n",
    "\n",
    "<h3>Naive Bayers: Multinominal</h3>\n",
    "<p>Naive bayers is a probabilistic machine learning algorithm, that is particualarly good at multiclassification. The algorithm is based on bayers theorem which can be expressed as: <img src=\"https://miro.medium.com/max/1020/1*tjcmj9cDQ-rHXAtxCu5bRQ.png\" aria-label=\"P(A|B) = P(B|A)P(A)/P(B)\">  .\n",
    "Naive bayers is often used solve several different AI tasks, but is often seen in text recognition, for example; determining if something is spam or not. The 'Naive' part stems from the assumption that the features are independent of each other which means that the presence of one feature does not affect the presence of another.</p>\n",
    "    \n",
    "<h3>Support Vector Machine</h3>\n",
    "<p>An SVM (Support Vector Machine) looks at the outliers in a dataset, and tries to define a linear line, called the hyper plane, between two outliers to determine whether something can be classified as A or B. This is however often difficult to achieve on all datasets, hence the dimensional space is increased, until a seperation can be made. There are several functions to achieve this effect, but overall it makes SVM rather costly to compute.<p>\n",
    "    \n",
    "<h3>Random Forest Classifier</h3>\n",
    "<p>Random Forest Classifier can be used for both classification and regression tasks, but is generally considered better for classifications tasks. The algorithm takes advantage of decision tree, and performs better the more data that is available, but is also rather cost heavy because there's no pruning of the trees. Consider the following example; training_data = [1,2,3,4,5,6], then one of the trees (t) might be given the following data: t1 = [2,3,2,2,4,4], this ensures tree diversity, whilst still maintaining data relevance. Furthermore random forest implements feature randomness, which is easier described, by describing how a tree 'normally' decides its path. Before a tree decides its path, it has to consider all previous features. Random forest, takes a path based on a random subset of features. The algorithm, when used for classification, has each tree voting for an outcome, and the aggregated outcome with the highest vote will be the result, unlike when used for regression, the average vote will be the result.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count vectors: 0.3964794635373009\n",
      "NB, tf-idf vectors: 0.3696563285834032\n",
      "SVM, Count vectors: 0.3763621123218776\n",
      "SVM, tf-idf vectors: 0.3730092204526404\n",
      "RF, Count vectors: 0.3520536462699078\n",
      "RF, tf-idf vectors: 0.35792120704107294\n"
     ]
    }
   ],
   "source": [
    "label = convert_arr_to_list(y_train)\n",
    "\n",
    "accuracy = train_model(classifier = naive_bayes.MultinomialNB(),\n",
    "                       X_train = X_train_count,\n",
    "                       y_train = label,\n",
    "                       X_test = X_test_count)\n",
    "print(f'NB, Count vectors: {accuracy}')\n",
    "\n",
    "accuracy = train_model(classifier = naive_bayes.MultinomialNB(),\n",
    "                       X_train = X_train_tfidf,\n",
    "                       y_train = label,\n",
    "                       X_test = X_test_tfidf)\n",
    "print(f'NB, tf-idf vectors: {accuracy}')\n",
    "\n",
    "\n",
    "accuracy = train_model(classifier = svm.SVC(),\n",
    "                       X_train = X_train_count,\n",
    "                       y_train = label,\n",
    "                       X_test = X_test_count)\n",
    "print(f'SVM, Count vectors: {accuracy}')\n",
    "\n",
    "accuracy = train_model(classifier = svm.SVC(),\n",
    "                       X_train = X_train_tfidf,\n",
    "                       y_train = label,\n",
    "                       X_test = X_test_tfidf)\n",
    "print(f'SVM, tf-idf vectors: {accuracy}')\n",
    "\n",
    "accuracy = train_model(classifier = ensemble.RandomForestClassifier(),\n",
    "                       X_train = X_train_count,\n",
    "                       y_train = label,\n",
    "                       X_test = X_test_count)\n",
    "print(f'RF, Count vectors: {accuracy}')\n",
    "\n",
    "accuracy = train_model(classifier = ensemble.RandomForestClassifier(),\n",
    "                       X_train = X_train_tfidf,\n",
    "                       y_train = label,\n",
    "                       X_test = X_test_tfidf)\n",
    "print(f'RF, tf-idf vectors: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusion</h2>\n",
    "<p>Several issues were raised during this project. Initially our dataset wasn't large enough to yield accurate results, hence we swapped to a larger dataset mid-project. The new dataset, as briefly touched upon in the introduction, contained several genres per movie, which raised new challenges. To overcome this, we selected the first out of n genres related to a movie, disregarding the remaining genres. As a result our models might predict a genre, that in fact is related to the movie, according to the dataset, but is still clasified as a wrong prediction. As a result all of our models are rather inaccurate despite having, what we believe is, sufficient data preprocessing and model training.\n",
    "\n",
    "Naive Bayers was the first algorithm we implemented, and because of the low accuracy score, we opted to implement SVM, which yielded an equally low score. Finally we implemented Random Forest, which yielded the lowest and most varying result of them all. After adjusting the different parameters, as described in the Feature Engineering section, we were unsuccessful in improving the results more than the current implementation.\n",
    "\n",
    "As a conclusion we believe that we've processed our data sufficiently, as well as trained our models correctly, but simply put we don't know how to handle multiple dependable variables.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Group</h2>\n",
    "<b>- Mikkel Wexøe Ertbjerg // cph-me209@cphbusiness.dk</b>\n",
    "\n",
    "<b>- Nikolai Sjhøholm Christiansen // cph-nc103@cphbusiness.dk</b>\n",
    "\n",
    "<b>- Nikolaj Dyring Jensen // cph-nj183@cphbusiness.dk</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
